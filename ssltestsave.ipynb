{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport os\nimport gc\nimport math\n\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch.optim\nfrom torch.utils.data import DataLoader, Dataset","metadata":{"execution":{"iopub.status.busy":"2023-03-10T07:13:55.72931Z","iopub.execute_input":"2023-03-10T07:13:55.730042Z","iopub.status.idle":"2023-03-10T07:13:58.461332Z","shell.execute_reply.started":"2023-03-10T07:13:55.729926Z","shell.execute_reply":"2023-03-10T07:13:58.460344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs(\"/kaggle/working/model/\")\nos.makedirs(\"/kaggle/working/image/\")\nos.makedirs(\"/kaggle/working/image/original/\")\nos.makedirs(\"/kaggle/working/image/mosaiced/\")\nos.makedirs(\"/kaggle/working/image/Unet/\")\nos.makedirs(\"/kaggle/working/image/SSLUnet/\")","metadata":{"execution":{"iopub.status.busy":"2023-03-10T07:14:02.938081Z","iopub.execute_input":"2023-03-10T07:14:02.93868Z","iopub.status.idle":"2023-03-10T07:14:02.943963Z","shell.execute_reply.started":"2023-03-10T07:14:02.938639Z","shell.execute_reply":"2023-03-10T07:14:02.9431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def CFA(pic: np.ndarray):\n    #h, w -> height,width(cv2-format)\n    h, w, _ = pic.shape\n    RGGB = np.array([[[1, 0, 0], [0, 1, 0]], [[0, 1, 0], [0, 0, 1]]])\n    time_h = int(np.ceil(h / 2))\n    time_w = int(np.ceil(w / 2))\n    CFA = np.tile(RGGB, (time_h, time_w, 1))\n    CFA = CFA[:h, :w, :]\n    processed = pic * CFA\n    return processed","metadata":{"execution":{"iopub.status.busy":"2023-01-22T08:59:16.545167Z","iopub.execute_input":"2023-01-22T08:59:16.547693Z","iopub.status.idle":"2023-01-22T08:59:16.558484Z","shell.execute_reply.started":"2023-01-22T08:59:16.547649Z","shell.execute_reply":"2023-01-22T08:59:16.556591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#对四维Tensor进行CFA滤波，pattern为滤波模式字符串（RGGB, BGGR等）\ndef CFA_d4(pic: torch.Tensor, pattern: str):\n    #b, c, h, w -> batch_size, channel, height, width\n    b, c, h, w = pic.shape\n    pic = pic.cuda()\n    \n    processed = torch.zeros(pic.shape)\n    processed = processed.cuda()\n    \n    RGGB = np.array([[[1, 0, 0], [0, 1, 0]], [[0, 1, 0], [0, 0, 1]]])\n    \n    #模板平铺的倍数\n    time_h = int(np.ceil(h / 2))\n    time_w = int(np.ceil(w / 2))\n    \n    #tiled RGGB\n    CFA = np.tile(RGGB, (time_h, time_w, 1))\n    processed2 = torch.clone(pic)\n    processed2 = processed2.cuda()\n   \n    CFA = CFA[:h, :w, :]\n    #CFA -> h*w*3,RGB\n    CFA3 = CFA.transpose((2,0,1))\n    #CFA3 -> 3*h*w,RGB\n    # numpy 转 tensor\n    CFA3 = torch.from_numpy(CFA3)\n    CFA3 = CFA3.cuda()\n    \n    for i in range(b):\n        if pattern == \"BGGR\":\n            #translate BGGR -> RGGB\n            processed2[i] = torch.roll(processed2[i],shifts=(-1, -1), dims = (1,2))\n        elif pattern == \"GBRG\":\n            #translate GBRG -> RGGB\n            processed2[i] = torch.roll(processed2[i],shifts=(-1, 0), dims = (1,2))\n        elif pattern == \"GRBG\":\n            #translate GRBG -> RGGB\n            processed2[i] = torch.roll(processed2[i],shifts=(0, -1), dims = (1,2))\n    for i in range(b):\n        processed2[i] = processed2[i] * CFA3\n        \n    return processed2\n\n","metadata":{"execution":{"iopub.status.busy":"2023-01-22T08:59:16.563091Z","iopub.execute_input":"2023-01-22T08:59:16.56582Z","iopub.status.idle":"2023-01-22T08:59:16.591667Z","shell.execute_reply.started":"2023-01-22T08:59:16.56578Z","shell.execute_reply":"2023-01-22T08:59:16.59059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def CFA_translate(pic: torch.Tensor, pattern:str):\n    # 将图像上移一个像素左移一个像素即可得到RGGB模式下的图片\n    #b, c, h, w -> batch_size, channel, height, width\n    b, c, h, w = pic.shape\n    pic = pic.cuda()\n    processed = torch.clone(pic)\n    \n    processed = processed.cuda()\n    BGGR = np.array([[[0, 0, 1], [0, 1, 0]], [[0, 1, 0], [1, 0, 0]]])\n    GBRG = np.array([[[0, 1, 0], [0, 0, 1]], [[1, 0, 0], [0, 1, 0]]])    \n    GRBG = np.array([[[0, 1, 0], [1, 0, 0]], [[0, 0, 1], [0, 1, 0]]])\n    time_h = int(np.ceil(h / 2))\n    time_w = int(np.ceil(w / 2))\n    if pattern == \"BGGR\":\n        CFA = np.tile(BGGR, (time_h, time_w,1))\n    elif pattern == \"GBRG\":\n        CFA = np.tile(GBRG, (time_h, time_w,1))\n    elif pattern == \"GRBG\":\n        CFA = np.tile(GRBG, (time_h, time_w,1))\n    CFA = CFA[:h,:w,:]\n    #CFA -> h*w*3,RGB\n    CFA3 = CFA.transpose((2,0,1))\n    #CFA3 -> 3*h*w,RGB\n    CFA3 = torch.from_numpy(CFA3)\n    CFA3 = CFA3.cuda()\n    \n    for i in range(b):\n        processed[i] = processed[i] * CFA3\n        if pattern == \"BGGR\":\n            processed[i] = torch.roll(processed[i],shifts=(1, 1), dims = (1,2))\n        elif pattern == \"GBRG\":\n            processed[i] = torch.roll(processed[i],shifts=(1, 0), dims = (1,2))\n        elif pattern == \"GBRG\":\n            processed[i] = torch.roll(processed[i],shifts=(0, 1), dims = (1,2))\n    return processed\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# img_o为输入，fil为卷积核，进行卷积，实现双线性插值\ndef my_fil(pic):\n    h, w, _ = pic.shape\n    #RGB -> BGR, to split\n    pic = pic[:,:,::-1]\n    #解决内存不连续问题\n    pic = pic.copy()\n    [B, G, R] = cv2.split(pic)\n    filter = np.array([[[0.25, 0., 0.25],\n                        [0.5, 0.25, 0.5],\n                        [0.25, 0., 0.25]],\n\n                       [[0.5, 0.25, 0.5],\n                        [1., 1., 1.],\n                        [0.5, 0.25, 0.5]],\n\n                       [[0.25, 0., 0.25],\n                        [0.5, 0.25, 0.5],\n                        [0.25, 0., 0.25]]])\n\n    B_fil = cv2.filter2D(B, -1, kernel=filter[:, :, 2])\n    G_fil = cv2.filter2D(G, -1, kernel=filter[:, :, 1])\n    R_fil = cv2.filter2D(R, -1, kernel=filter[:, :, 0])\n\n    pic_new = cv2.merge([B_fil, G_fil, R_fil])\n    #BGR -> RGB\n    pic_new = pic_new[:,:,::-1]\n    #解决内存不连续问题\n    pic_new = pic_new.copy()\n    return pic_new\n\ndef my_fil_d4(pic):\n    #b, c, h, w -> batch_size, channel, height, width\n    b, c, h, w = pic.shape\n    filter = np.array([[[0.25, 0., 0.25],\n                        [0.5, 0.25, 0.5],\n                        [0.25, 0., 0.25]],\n\n                       [[0.5, 0.25, 0.5],\n                        [1., 1., 1.],\n                        [0.5, 0.25, 0.5]],\n\n                       [[0.25, 0., 0.25],\n                        [0.5, 0.25, 0.5],\n                        [0.25, 0., 0.25]]])\n    \n    # pic转numpy\n    pic = pic.detach().cpu().numpy() if pic.requires_grad else pic.cpu().numpy()\n    pic3 = pic\n    for i in range(b):\n        pic2 = pic[i]\n        #CHW -> HWC, to split\n        pic2 = pic2.transpose((1, 2, 0))\n        #RGB -> BGR, to split\n        pic2 = pic2[:,:,::-1]\n        #解决内存不连续问题\n        pic2 = pic2.copy()\n        \n        [B, G, R] = cv2.split(pic2)\n        \n        B_fil = cv2.filter2D(B, -1, kernel=filter[:, :, 2])\n        G_fil = cv2.filter2D(G, -1, kernel=filter[:, :, 1])\n        R_fil = cv2.filter2D(R, -1, kernel=filter[:, :, 0])\n        \n        pic_new = cv2.merge([B_fil, G_fil, R_fil])\n        #BGR -> RGB\n        pic_new = pic_new[:,:,::-1]\n        #解决内存不连续问题\n        pic_new = pic_new.copy()\n        #HWC -> CHW\n        pic_new = pic_new.transpose((2, 0, 1))\n        pic3[i] = pic_new\n    pic3 = torch.from_numpy(pic3)\n    pic3 = pic3.cuda()\n    return pic3\n        \n        ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyGehlerTrainDataset(Dataset):\n    def __init__(self, filepath, transform=None):\n        self.filepath = filepath\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        imgs = os.listdir(self.filepath)\n        path = self.filepath + imgs[index]\n        \n        temp = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n        #BGR -> RGB\n        temp = temp[:,:,::-1]\n        #解决内存不连续问题\n        temp = temp.copy()\n        temp = np.float64(temp)\n        h, w, _ = temp.shape\n        \n        if h == 2193 or h == 1460:\n            temp = np.maximum(0., temp - 129.)\n        \n        temp = temp[:1024,:1024,:]\n\n        #归一化\n        temp = temp / 4095.0\n        \n        label = CFA(temp)\n        data = my_fil(CFA(temp))\n        \n        if self.transform is not None:\n            data = self.transform(data)\n            label = self.transform(label)\n            \n        return data, label\n\n    def __len__(self):\n        return len(os.listdir(self.filepath))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyGehlerTestDataset(Dataset):\n    def __init__(self, filepath, transform=None):\n        self.filepath = filepath\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        imgs = os.listdir(self.filepath)\n        path = self.filepath + imgs[index]\n        \n        temp = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n        #BGR -> RGB\n        temp = temp[:,:,::-1]\n        #解决内存不连续问题\n        temp = temp.copy()\n        temp = np.float64(temp)\n        h, w, _ = temp.shape\n        \n        if h == 2193 or h == 1460:\n            temp = np.maximum(0., temp - 129.)\n        \n        temp = temp[:1024,:1024,:]\n\n        #归一化\n        temp = temp / 4095.0\n        \n        label = temp\n        data = my_fil(CFA(temp))\n        \n        if self.transform is not None:\n            data = self.transform(data)\n            label = self.transform(label)\n            \n        return data, label\n\n    def __len__(self):\n        return len(os.listdir(self.filepath))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([transforms.ToTensor()])\ntrain_batch_size = 1\ntrain_number_epoch = 30\n\ntrain_dir2 = \"/kaggle/input/gehler-shi-train/\"\ntest_dir = \"/kaggle/input/gehler-shi-test/\"\n\ntrainset2 = MyGehlerTrainDataset(train_dir2, transform=transform)\ntrainloader2 = DataLoader(trainset2, batch_size=train_batch_size, shuffle=False)\ntestset = MyGehlerTestDataset(test_dir, transform=transform)\ntestloader = DataLoader(testset, batch_size=1, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-22T08:59:16.706545Z","iopub.execute_input":"2023-01-22T08:59:16.708901Z","iopub.status.idle":"2023-01-22T09:04:50.973389Z","shell.execute_reply.started":"2023-01-22T08:59:16.708866Z","shell.execute_reply":"2023-01-22T09:04:50.972285Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 基本卷积块\nclass Conv(nn.Module):\n    def __init__(self, C_in, C_out):\n        super(Conv, self).__init__()\n        self.layer = nn.Sequential(\n\n            nn.Conv2d(C_in, C_out, 3, 1, 1),\n            nn.LeakyReLU(),\n\n            nn.Conv2d(C_out, C_out, 3, 1, 1),\n            nn.LeakyReLU(),\n        )\n\n    def forward(self, x):\n        return self.layer(x)\n\n\n# 下采样模块\nclass DownSampling(nn.Module):\n    def __init__(self, C):\n        super(DownSampling, self).__init__()\n        self.Down = nn.Sequential(\n            # 使用卷积进行2倍的下采样，通道数不变\n            nn.Conv2d(C, C, 3, 2, 1),\n            nn.LeakyReLU()\n        )\n\n    def forward(self, x):\n        return self.Down(x)\n\n\n# 上采样模块\nclass UpSampling(nn.Module):\n\n    def __init__(self, C):\n        super(UpSampling, self).__init__()\n        # 特征图大小扩大2倍，通道数减半\n        self.Up = nn.Conv2d(C, C // 2, 1, 1)\n\n    def forward(self, x, r):\n        # 使用邻近插值进行上采样\n        up = F.interpolate(x, scale_factor=2, mode=\"nearest\")\n        x = self.Up(up)\n        # 拼接，当前上采样的，和之前下采样过程中的\n        return torch.cat((x, r), 1)\n\n\n# 主干网络\nclass UNet(nn.Module):\n\n    def __init__(self):\n        super(UNet, self).__init__()\n\n        self.C1 = Conv(3, 64)\n        self.D1 = DownSampling(64)\n        self.C2 = Conv(64, 128)\n        self.D2 = DownSampling(128)\n        self.C3 = Conv(128, 256)\n        self.D3 = DownSampling(256)\n        self.C4 = Conv(256, 512)\n        self.D4 = DownSampling(512)\n        self.C5 = Conv(512, 1024)\n\n        # 4次上采样\n        self.U1 = UpSampling(1024)\n        self.C6 = Conv(1024, 512)\n        self.U2 = UpSampling(512)\n        self.C7 = Conv(512, 256)\n        self.U3 = UpSampling(256)\n        self.C8 = Conv(256, 128)\n        self.U4 = UpSampling(128)\n        self.C9 = Conv(128, 64)\n\n        self.Th = torch.nn.Sigmoid()\n        self.pred = torch.nn.Conv2d(64, 3, 3, 1, 1)\n\n    def forward(self, x):\n        # 下采样部分\n        R1 = self.C1(x)\n        R2 = self.C2(self.D1(R1))\n        R3 = self.C3(self.D2(R2))\n        R4 = self.C4(self.D3(R3))\n        Y1 = self.C5(self.D4(R4))\n\n        # 上采样部分\n        # 上采样的时候需要拼接起来\n        O1 = self.C6(self.U1(Y1, R4))\n        O2 = self.C7(self.U2(O1, R3))\n        O3 = self.C8(self.U3(O2, R2))\n        O4 = self.C9(self.U4(O3, R1))\n        return self.Th(self.pred(O4))\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-01-22T09:04:50.97524Z","iopub.execute_input":"2023-01-22T09:04:50.975689Z","iopub.status.idle":"2023-01-22T09:04:50.996942Z","shell.execute_reply.started":"2023-01-22T09:04:50.975647Z","shell.execute_reply":"2023-01-22T09:04:50.995682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net = UNet().cuda()\nloss_func = nn.MSELoss()\nnet.load_state_dict(torch.load('/kaggle/input/best-pretrain-unet-230320/best_pretrain_unet_230320.pth'))\nbest_train_loss = float('inf')\nbest_test_loss = float('inf')\nlr = 1e-5\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=lr, weight_decay=1e-4)\ntrain_dataloader = trainloader2\ntest_dataloader = testloader\nepochs = train_number_epoch\n","metadata":{"execution":{"iopub.status.busy":"2023-01-22T09:04:51.002057Z","iopub.execute_input":"2023-01-22T09:04:51.002415Z","iopub.status.idle":"2023-01-22T09:04:56.715009Z","shell.execute_reply.started":"2023-01-22T09:04:51.002372Z","shell.execute_reply":"2023-01-22T09:04:56.713906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Freeze paarameters\nlayers = len(list(net.named_parameters()))\nprint(\"layers = \", layers)\nfor i, layer in enumerate(net.named_parameters(), 0):\n    if i < 0.9 * layers:\n        layer[1].requires_grad = False\nprint(\"90% of the parameters are freezed\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def SSL_train(trainloader, model, loss_func, optimizer):\n    global best_train_loss\n    device = torch.device('cuda')\n    model = model.to(device)\n    for epoch in range(0, epochs):\n        # train part\n        # model.train()\n        \n        total_train_loss = 0\n        \n        #初始化三通道PSNR值与CPSNR值\n        total_psnr_r = 0\n        total_psnr_g = 0\n        total_psnr_b = 0\n        total_cpsnr = 0\n        \n        counter = 0\n        for i, data in enumerate(trainloader, 0):\n            input_pic, label = data\n            #转移到GPU上，类型变为float以与模型参数类型匹配\n            input_pic, label = input_pic.to(device, dtype=torch.float), label.to(device, dtype=torch.float)\n            \n            # output 已经双线性插值 进网络重建，得到三通道图片\n            output = model(input_pic)\n            \n            # 采样 pattern2并双线性插值\n            output2 = CFA_translate(output, \"BGGR\")\n                \n            output2 = my_fil_d4(output2)\n            \n            output2 = model(output2)\n            \n            output2 = CFA_d4(output2, \"BGGR\")\n            \n            # 采样 pattern3并双线性插值\n            output3 = CFA_translate(output, \"GBRG\")\n            \n            output3 = my_fil_d4(output3)\n            \n            output3 = model(output3)\n            \n            output3 = CFA_d4(output3, \"GBRG\")\n\n            # 采样 pattern4\n            output4 = CFA_translate(output, \"GRBG\")\n            \n            output4 = my_fil_d4(output4)\n             \n            output4 = model(output4)\n            \n            output4 = CFA_d4(output4, \"GRBG\")\n            \n            #设置去除边界的宽度\n            bound = 1\n            \n            label_b = label[:, :, bound:-bound,bound:-bound]\n            output2_b = output2[:, :, bound:-bound,bound:-bound]\n            output3_b = output3[:, :, bound:-bound,bound:-bound]\n            output4_b = output4[:, :, bound:-bound,bound:-bound]\n            \n            optimizer.zero_grad()\n            \n            loss = loss_func(output2_b, label_b)\n            loss.requires_grad_(True)\n            loss.backward()\n            \n            optimizer.step()\n            total_train_loss += loss.item()\n            \n            #为计算PSNR部分而进行MSE的计算\n\n            output = model(input_pic)\n            \n            output = CFA_d4(output, \"RGGB\")\n            \n            #RGB三通道的MSE值\n\n            mse_r = loss_func(output[:, 0],\n                             label[:, 0])\n            mse_g = loss_func(output[:, 1],\n                             label[:, 1])\n            mse_b = loss_func(output[:, 2],\n                             label[:, 2])\n            #CPSNR，即三通道PSNR值的平均值\n            cmse = loss_func(output,\n                             label)\n\n            #计算所有图片RGB三通道的PSNR值及CPSNR之和\n            if mse_r.item() < 1.0e-10:  # 均方误差小到过分了\n                total_psnr_r += 100\n            else:\n                total_psnr_r += 20 * math.log10(1 / math.sqrt(mse_r.item()))\n\n            if mse_g.item() < 1.0e-10:  # 均方误差小到过分了\n                total_psnr_g += 100\n            else:\n                total_psnr_g += 20 * math.log10(1 / math.sqrt(mse_g.item()))\n\n            if mse_b.item() < 1.0e-10:  # 均方误差小到过分了\n                total_psnr_b += 100\n            else:\n                total_psnr_b += 20 * math.log10(1 / math.sqrt(mse_b.item()))\n\n            if cmse.item() < 1.0e-10:  # 均方误差小到过分了\n                total_cpsnr += 100\n            else:\n                total_cpsnr += 20 * math.log10(1 / math.sqrt(cmse.item()))\n\n            counter += 1\n\n        train_loss_avg = total_train_loss / counter\n\n        #计算所有图片RGB三通道的PSNR值及CPSNR之均值\n        psnr_r_avg = total_psnr_r / counter\n        psnr_g_avg = total_psnr_g / counter\n        psnr_b_avg = total_psnr_b / counter\n        cpsnr_avg = total_cpsnr / counter\n        \n        print(\"Epoch number: {} , Train loss: {:.4f}\\nPSNR_R: {:.4f}, PSNR_G: {:.4f}, PSNR_B: {:.4f}, CPSNR: {:.4f}\\n\".format(epoch, train_loss_avg, psnr_r_avg, psnr_g_avg, psnr_b_avg, cpsnr_avg))\n        if train_loss_avg < best_train_loss:\n            best_train_loss = train_loss_avg\n            torch.save(model.state_dict(), '/kaggle/working/SSLbest_unet1p09.pth')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def SSL_test(testloader, model, loss_func, save_result, SSLflag):\n    device = torch.device('cuda')\n    model = model.to(device)\n    # test part\n    model.eval()\n    total_test_loss = 0\n\n    #初始化三通道PSNR值与CPSNR值\n    total_psnr_r = 0\n    total_psnr_g = 0\n    total_psnr_b = 0\n    total_cpsnr = 0\n\n    counter = 0\n\n    with torch.no_grad():\n        for j, data in enumerate(testloader, 0):\n            input_pic, label = data\n\n            #CFA滤波与双线性插值的过程已在test_data_get函数中完成\n            input_pic, label = input_pic.to(device, dtype=torch.float), label.to(device, dtype=torch.float)\n            # 进网络\n            \n            output = model(input_pic)\n            if save_result:\n                #1*3(RGB)*H*W -> H*W*3(RGB)\n                labelImgTensor = label\n                labelImg = labelImgTensor[0].detach().cpu().numpy().transpose((1,2,0))\n                #rgb_range 1->255\n                labelImg = np.uint8(labelImg*255.)\n                labelImg = cv2.cvtColor(labelImg, cv2.COLOR_RGB2BGR)\n                cv2.imwrite(\"/kaggle/working/image/original/{}.png\".format(j), labelImg)\n                \n                #1*3(RGB)*H*W -> H*W*3(RGB)\n                labelImgTensor = CFA_d4(label, \"RGGB\")\n                labelImg = labelImgTensor[0].detach().cpu().numpy().transpose((1,2,0))\n                #rgb_range 1->255\n                labelImg = np.uint8(labelImg*255.)\n                labelImg = cv2.cvtColor(labelImg, cv2.COLOR_RGB2BGR)\n                cv2.imwrite(\"/kaggle/working/image/mosaiced/{}.png\".format(j), labelImg)\n            \n                #1*3(RGB)*H*W -> H*W*3(RGB)\n                img = output[0].detach().cpu().numpy().transpose((1,2,0))\n                #rgb_range 1->255\n                img = np.uint8(img*255.)\n                img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n                if SSLflag:\n                    cv2.imwrite(\"/kaggle/working/image/SSLUnet/{}.png\".format(j), img)\n                else:\n                    cv2.imwrite(\"/kaggle/working/image/Unet/{}.png\".format(j), img)\n\n            \n            output = output.cuda()\n\n            loss = loss_func(output, label)\n\n            total_test_loss += loss.item()\n\n            #为计算PSNR部分而进行MSE的计算\n\n            #RGB三通道的MSE值\n\n            mse_r = loss_func(output[:, 0, :, :],\n                             label[:, 0, :, :])\n            mse_g = loss_func(output[:, 1, :, :],\n                             label[:, 1, :, :])\n            mse_b = loss_func(output[:, 2, :, :],\n                             label[:, 2, :, :])\n            #CPSNR，即三通道PSNR值的平均值\n            cmse = loss_func(output, label)\n\n            #计算所有图片RGB三通道的PSNR值及CPSNR之和\n            if mse_r.item() < 1.0e-10:  # 均方误差小到过分了\n                total_psnr_r += 100\n            else:\n                total_psnr_r += 20 * math.log10(1 / math.sqrt(mse_r.item()))\n\n            if mse_g.item() < 1.0e-10:  # 均方误差小到过分了\n                total_psnr_g += 100\n            else:\n                total_psnr_g += 20 * math.log10(1 / math.sqrt(mse_g.item()))\n\n            if mse_b.item() < 1.0e-10:  # 均方误差小到过分了\n                total_psnr_b += 100\n            else:\n                total_psnr_b += 20 * math.log10(1 / math.sqrt(mse_b.item()))\n\n            if cmse.item() < 1.0e-10:  # 均方误差小到过分了\n                total_cpsnr += 100\n            else:\n                total_cpsnr += 20 * math.log10(1 / math.sqrt(cmse.item()))\n\n            counter += 1\n\n        test_loss_avg = total_test_loss / counter\n\n        #计算所有图片RGB三通道的PSNR值及CPSNR之均值\n        psnr_r_avg = total_psnr_r / counter\n        psnr_g_avg = total_psnr_g / counter\n        psnr_b_avg = total_psnr_b / counter\n        cpsnr_avg = total_cpsnr / counter\n\n        print(\"Test loss: {:.4f}\\nPSNR_R: {:.4f}, PSNR_G: {:.4f}, PSNR_B: {:.4f}, CPSNR: {:.4f}\\n\".format(test_loss_avg, psnr_r_avg, psnr_g_avg, psnr_b_avg, cpsnr_avg))        \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"The Test loss and PSNR before SSL:\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SSL_test(test_dataloader, net, loss_func, False, False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SSL_train(train_dataloader, net, loss_func, optimizer)","metadata":{"execution":{"iopub.status.busy":"2023-01-22T09:04:56.737368Z","iopub.execute_input":"2023-01-22T09:04:56.737754Z","iopub.status.idle":"2023-01-22T09:05:02.657485Z","shell.execute_reply.started":"2023-01-22T09:04:56.737712Z","shell.execute_reply":"2023-01-22T09:05:02.65528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net.load_state_dict(torch.load('/kaggle/working/SSLbest_unet1p09.pth'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"The Test loss and PSNR after SSL:\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SSL_test(test_dataloader, net, loss_func, True, True)","metadata":{},"execution_count":null,"outputs":[]}]}