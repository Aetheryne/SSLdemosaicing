{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c2c574a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-16T00:21:25.832234Z",
     "iopub.status.busy": "2023-03-16T00:21:25.831670Z",
     "iopub.status.idle": "2023-03-16T00:21:29.072456Z",
     "shell.execute_reply": "2023-03-16T00:21:29.071476Z"
    },
    "papermill": {
     "duration": 3.250059,
     "end_time": "2023-03-16T00:21:29.075040",
     "exception": false,
     "start_time": "2023-03-16T00:21:25.824981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import gc\n",
    "import math\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader, Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69fc8602",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T00:21:29.085505Z",
     "iopub.status.busy": "2023-03-16T00:21:29.084437Z",
     "iopub.status.idle": "2023-03-16T00:21:29.091500Z",
     "shell.execute_reply": "2023-03-16T00:21:29.090604Z"
    },
    "papermill": {
     "duration": 0.013956,
     "end_time": "2023-03-16T00:21:29.093498",
     "exception": false,
     "start_time": "2023-03-16T00:21:29.079542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def CFA(pic: np.ndarray):\n",
    "    #h, w -> height,width(cv2-format)\n",
    "    h, w, _ = pic.shape\n",
    "    RGGB = np.array([[[1, 0, 0], [0, 1, 0]], [[0, 1, 0], [0, 0, 1]]])\n",
    "    #模板平铺的倍数\n",
    "    time_h = int(np.ceil(h / 2))\n",
    "    time_w = int(np.ceil(w / 2))\n",
    "    #平铺模板\n",
    "    CFA = np.tile(RGGB, (time_h, time_w, 1))\n",
    "    CFA = CFA[:h, :w, :]\n",
    "    #CFA模板滤波\n",
    "    processed = pic * CFA\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6afce16b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T00:21:29.102505Z",
     "iopub.status.busy": "2023-03-16T00:21:29.102246Z",
     "iopub.status.idle": "2023-03-16T00:21:29.113394Z",
     "shell.execute_reply": "2023-03-16T00:21:29.112579Z"
    },
    "papermill": {
     "duration": 0.017993,
     "end_time": "2023-03-16T00:21:29.115267",
     "exception": false,
     "start_time": "2023-03-16T00:21:29.097274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#对四维Tensor进行CFA滤波，pattern为滤波模式字符串（RGGB, BGGR等）\n",
    "def CFA_d4(pic: torch.Tensor, pattern: str):\n",
    "    #b, c, h, w -> batch_size, channel, height, width\n",
    "    b, c, h, w = pic.shape\n",
    "    pic = pic.cuda()\n",
    "    \n",
    "    processed = torch.zeros(pic.shape)\n",
    "    processed = processed.cuda()\n",
    "    \n",
    "    RGGB = np.array([[[1, 0, 0], [0, 1, 0]], [[0, 1, 0], [0, 0, 1]]])\n",
    "    \n",
    "    #模板平铺的倍数\n",
    "    time_h = int(np.ceil(h / 2))\n",
    "    time_w = int(np.ceil(w / 2))\n",
    "    \n",
    "    #tiled RGGB\n",
    "    CFA = np.tile(RGGB, (time_h, time_w, 1))\n",
    "    processed2 = torch.clone(pic)\n",
    "    processed2 = processed2.cuda()\n",
    "   \n",
    "    CFA = CFA[:h, :w, :]\n",
    "    #CFA -> h*w*3,RGB\n",
    "    CFA3 = CFA.transpose((2,0,1))\n",
    "    #CFA3 -> 3*h*w,RGB\n",
    "    # numpy 转 tensor\n",
    "    CFA3 = torch.from_numpy(CFA3)\n",
    "    CFA3 = CFA3.cuda()\n",
    "    \n",
    "    for i in range(b):\n",
    "        if pattern == \"BGGR\":\n",
    "            #translate BGGR -> RGGB\n",
    "            processed2[i] = torch.roll(processed2[i],shifts=(-1, -1), dims = (1,2))\n",
    "        elif pattern == \"GBRG\":\n",
    "            #translate GBRG -> RGGB\n",
    "            processed2[i] = torch.roll(processed2[i],shifts=(-1, 0), dims = (1,2))\n",
    "        elif pattern == \"GRBG\":\n",
    "            #translate GRBG -> RGGB\n",
    "            processed2[i] = torch.roll(processed2[i],shifts=(0, -1), dims = (1,2))\n",
    "    for i in range(b):\n",
    "        processed2[i] = processed2[i] * CFA3\n",
    "        \n",
    "    return processed2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7271e50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T00:21:29.124907Z",
     "iopub.status.busy": "2023-03-16T00:21:29.124080Z",
     "iopub.status.idle": "2023-03-16T00:21:29.138445Z",
     "shell.execute_reply": "2023-03-16T00:21:29.137521Z"
    },
    "papermill": {
     "duration": 0.021184,
     "end_time": "2023-03-16T00:21:29.140414",
     "exception": false,
     "start_time": "2023-03-16T00:21:29.119230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# img_o为输入，fil为卷积核，进行卷积，实现双线性插值\n",
    "def my_fil(pic):\n",
    "    h, w, _ = pic.shape\n",
    "    #RGB -> BGR, to split\n",
    "    pic = pic[:,:,::-1]\n",
    "    #解决内存不连续问题\n",
    "    pic = pic.copy()\n",
    "    [B, G, R] = cv2.split(pic)\n",
    "    filter = np.array([[[0.25, 0., 0.25],\n",
    "                        [0.5, 0.25, 0.5],\n",
    "                        [0.25, 0., 0.25]],\n",
    "\n",
    "                       [[0.5, 0.25, 0.5],\n",
    "                        [1., 1., 1.],\n",
    "                        [0.5, 0.25, 0.5]],\n",
    "\n",
    "                       [[0.25, 0., 0.25],\n",
    "                        [0.5, 0.25, 0.5],\n",
    "                        [0.25, 0., 0.25]]])\n",
    "\n",
    "    B_fil = cv2.filter2D(B, -1, kernel=filter[:, :, 2])\n",
    "    G_fil = cv2.filter2D(G, -1, kernel=filter[:, :, 1])\n",
    "    R_fil = cv2.filter2D(R, -1, kernel=filter[:, :, 0])\n",
    "\n",
    "    pic_new = cv2.merge([B_fil, G_fil, R_fil])\n",
    "    #BGR -> RGB\n",
    "    pic_new = pic_new[:,:,::-1]\n",
    "    #解决内存不连续问题\n",
    "    pic_new = pic_new.copy()\n",
    "    return pic_new\n",
    "\n",
    "def my_fil_d4(pic):\n",
    "    #b, c, h, w -> batch_size, channel, height, width\n",
    "    b, c, h, w = pic.shape\n",
    "    filter = np.array([[[0.25, 0., 0.25],\n",
    "                        [0.5, 0.25, 0.5],\n",
    "                        [0.25, 0., 0.25]],\n",
    "\n",
    "                       [[0.5, 0.25, 0.5],\n",
    "                        [1., 1., 1.],\n",
    "                        [0.5, 0.25, 0.5]],\n",
    "\n",
    "                       [[0.25, 0., 0.25],\n",
    "                        [0.5, 0.25, 0.5],\n",
    "                        [0.25, 0., 0.25]]])\n",
    "    \n",
    "    # pic转numpy\n",
    "    pic = pic.detach().cpu().numpy() if pic.requires_grad else pic.cpu().numpy()\n",
    "    pic3 = pic\n",
    "    for i in range(b):\n",
    "        pic2 = pic[i]\n",
    "        #CHW -> HWC, to split\n",
    "        pic2 = pic2.transpose((1, 2, 0))\n",
    "        #RGB -> BGR, to split\n",
    "        pic2 = pic2[:,:,::-1]\n",
    "        #解决内存不连续问题\n",
    "        pic2 = pic2.copy()\n",
    "        \n",
    "        [B, G, R] = cv2.split(pic2)\n",
    "        \n",
    "        B_fil = cv2.filter2D(B, -1, kernel=filter[:, :, 2])\n",
    "        G_fil = cv2.filter2D(G, -1, kernel=filter[:, :, 1])\n",
    "        R_fil = cv2.filter2D(R, -1, kernel=filter[:, :, 0])\n",
    "        \n",
    "        pic_new = cv2.merge([B_fil, G_fil, R_fil])\n",
    "        #BGR -> RGB\n",
    "        pic_new = pic_new[:,:,::-1]\n",
    "        #解决内存不连续问题\n",
    "        pic_new = pic_new.copy()\n",
    "        #HWC -> CHW\n",
    "        pic_new = pic_new.transpose((2, 0, 1))\n",
    "        pic3[i] = pic_new\n",
    "    pic3 = torch.from_numpy(pic3)\n",
    "    pic3 = pic3.cuda()\n",
    "    return pic3\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "733a7a23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T00:21:29.149359Z",
     "iopub.status.busy": "2023-03-16T00:21:29.149109Z",
     "iopub.status.idle": "2023-03-16T00:21:29.154669Z",
     "shell.execute_reply": "2023-03-16T00:21:29.153826Z"
    },
    "papermill": {
     "duration": 0.012483,
     "end_time": "2023-03-16T00:21:29.156705",
     "exception": false,
     "start_time": "2023-03-16T00:21:29.144222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Datasets(Dataset):\n",
    "    def __init__(self, data, label, transform=None):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index]\n",
    "        label = self.label[index]\n",
    "        if self.transform is not None:\n",
    "            data = self.transform(data)\n",
    "            label = self.transform(label)\n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81ecaae4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T00:21:29.166156Z",
     "iopub.status.busy": "2023-03-16T00:21:29.165562Z",
     "iopub.status.idle": "2023-03-16T00:21:29.180347Z",
     "shell.execute_reply": "2023-03-16T00:21:29.179563Z"
    },
    "papermill": {
     "duration": 0.021531,
     "end_time": "2023-03-16T00:21:29.182276",
     "exception": false,
     "start_time": "2023-03-16T00:21:29.160745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_data_get(data_path):\n",
    "    img_list = []\n",
    "    labels = []\n",
    "    imgs = os.listdir(data_path)\n",
    "\n",
    "    for i in range(len(imgs)):\n",
    "        path = data_path + imgs[i]\n",
    "        temp = cv2.imread(path)\n",
    "        #BGR -> RGB\n",
    "        temp = temp[:,:,::-1]\n",
    "        #解决内存不连续问题\n",
    "        temp = temp.copy()\n",
    "        temp = np.float64(temp)\n",
    "        h, w, _ = temp.shape\n",
    "\n",
    "        temp = temp[0:(h - h%16), 0:(w-w%16), :]  # 避免上下采样时出现维度不匹配问题\n",
    "\n",
    "        #归一化\n",
    "        temp = temp / 255.0\n",
    "        \n",
    "        temp_label = temp\n",
    "        temp = CFA(temp)\n",
    "        temp = my_fil(temp)\n",
    "        \n",
    "        img_list.append(temp)\n",
    "        labels.append(temp_label)\n",
    "\n",
    "    train_list, train_label = img_list, labels\n",
    "    print(\"Train data get complete.\")\n",
    "    return train_list, train_label\n",
    "\n",
    "def val_data_get(data_path):\n",
    "    img_list = []\n",
    "    labels = []\n",
    "    imgs = os.listdir(data_path)\n",
    "\n",
    "    for i in range(len(imgs)):\n",
    "        path = data_path + imgs[i]\n",
    "        temp = cv2.imread(path)\n",
    "        #BGR -> RGB\n",
    "        temp = temp[:,:,::-1]\n",
    "        #解决内存不连续问题\n",
    "        temp = temp.copy()\n",
    "        temp = np.float64(temp)\n",
    "        h, w, _ = temp.shape\n",
    "\n",
    "        temp = temp[0:(h - h%16), 0:(w-w%16), :]  # 避免上下采样时出现维度不匹配问题\n",
    "        \n",
    "        #归一化\n",
    "        temp = temp / 255.0\n",
    "        \n",
    "        temp_label = temp\n",
    "        temp = CFA(temp)\n",
    "        temp = my_fil(temp)\n",
    "        \n",
    "        img_list.append(temp)\n",
    "        labels.append(temp_label)\n",
    "        \n",
    "    val_list, val_label = img_list, labels\n",
    "    print(\"Validation data get complete.\")\n",
    "    return val_list, val_label\n",
    "\n",
    "def Gehler_Shi_test_data_get(data_path):\n",
    "    img_list = []\n",
    "    labels = []\n",
    "    imgs = os.listdir(data_path)\n",
    "\n",
    "    for i in range(len(imgs)):\n",
    "        \n",
    "        path = data_path + imgs[i]\n",
    "        temp = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "        #BGR -> RGB\n",
    "        temp = temp[:,:,::-1]\n",
    "        #解决内存不连续问题\n",
    "        temp = temp.copy()\n",
    "        temp = np.float64(temp)\n",
    "\n",
    "        # 去除black level(对于CANON5D的图片)\n",
    "        h, w, _ = temp.shape\n",
    "        if h == 2193 or h == 1460:\n",
    "            temp = np.maximum(0., temp - 129.)\n",
    "\n",
    "        temp = temp / 4095.  # 归一化(参考代码中是除以最大值，或许可以考虑除以4095)\n",
    "        h, w, _ = temp.shape\n",
    "\n",
    "        #对Gehler_Shi测试集不进行切分\n",
    "        #将图像的大小缩小为16的倍数以适应UNET\n",
    "        #为了让数据大小统一，切一个统一的大小（设为1344*1344）\n",
    "        temp = temp[0:1344, 0:1344, :]\n",
    "        \n",
    "        #label为原值，input经过CFA滤波并双线性插值\n",
    "        temp_label = temp\n",
    "        temp = np.float64(CFA(temp))\n",
    "        temp = my_fil(temp)\n",
    "\n",
    "        img_list.append(temp)\n",
    "        labels.append(temp_label)\n",
    "\n",
    "    test_list, test_label = img_list, labels\n",
    "    print(\"Gehler-Shi test data get complete.\")\n",
    "    return test_list, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e45a35b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T00:21:29.191327Z",
     "iopub.status.busy": "2023-03-16T00:21:29.191071Z",
     "iopub.status.idle": "2023-03-16T00:24:41.225447Z",
     "shell.execute_reply": "2023-03-16T00:24:41.224148Z"
    },
    "papermill": {
     "duration": 192.041446,
     "end_time": "2023-03-16T00:24:41.227616",
     "exception": false,
     "start_time": "2023-03-16T00:21:29.186170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data get complete.\n",
      "Validation data get complete.\n",
      "Gehler-Shi test data get complete.\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_batch_size = 1\n",
    "train_number_epoch = 2\n",
    "\n",
    "train_dir1 = \"/kaggle/input/moiretrain10000/\"\n",
    "val_dir = \"/kaggle/input/moireval/\"\n",
    "test_dir = \"/kaggle/input/gehlertest10/\"\n",
    "\n",
    "train_list1, train_label1 = train_data_get(train_dir1)\n",
    "val_list, val_label = val_data_get(val_dir)\n",
    "test_list, test_label = Gehler_Shi_test_data_get(val_dir)\n",
    "\n",
    "trainset1 = Datasets(data=train_list1, label=train_label1, transform=transform)\n",
    "trainloader1 = DataLoader(trainset1, batch_size=train_batch_size, shuffle=True)\n",
    "valset = Datasets(data=val_list, label=val_label, transform=transform)\n",
    "valloader = DataLoader(valset, batch_size=1, shuffle=True)\n",
    "testset = Datasets(data=test_list, label=test_label, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e2c944c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T00:24:41.238235Z",
     "iopub.status.busy": "2023-03-16T00:24:41.237951Z",
     "iopub.status.idle": "2023-03-16T00:24:41.273903Z",
     "shell.execute_reply": "2023-03-16T00:24:41.272883Z"
    },
    "papermill": {
     "duration": 0.043676,
     "end_time": "2023-03-16T00:24:41.275988",
     "exception": false,
     "start_time": "2023-03-16T00:24:41.232312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# common\n",
    "\n",
    "class BasicBlock(nn.Sequential):\n",
    "    def __init__(\n",
    "            self, conv, in_channels, out_channels, kernel_size, stride=1, bias=True,\n",
    "            bn=False, act=nn.PReLU()):\n",
    "\n",
    "        m = [conv(in_channels, out_channels, kernel_size, bias=bias)]\n",
    "        if bn:\n",
    "            m.append(nn.BatchNorm2d(out_channels))\n",
    "        if act is not None:\n",
    "            m.append(act)\n",
    "\n",
    "        super(BasicBlock, self).__init__(*m)\n",
    "\n",
    "\n",
    "def default_conv(in_channels, out_channels, kernel_size, stride=1, bias=True):\n",
    "    return nn.Conv2d(\n",
    "        in_channels, out_channels, kernel_size,\n",
    "        padding=(kernel_size // 2), stride=stride, bias=bias)\n",
    "\n",
    "\n",
    "class MeanShift(nn.Conv2d):\n",
    "    def __init__(\n",
    "            self, rgb_range,\n",
    "            rgb_mean=(0.4488, 0.4371, 0.4040), rgb_std=(1.0, 1.0, 1.0), sign=-1):\n",
    "        super(MeanShift, self).__init__(3, 3, kernel_size=1)\n",
    "        std = torch.Tensor(rgb_std)\n",
    "        self.weight.data = torch.eye(3).view(3, 3, 1, 1) / std.view(3, 1, 1, 1)\n",
    "        self.bias.data = sign * rgb_range * torch.Tensor(rgb_mean) / std\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self, conv, n_feats, kernel_size,\n",
    "            bias=True, bn=False, act=nn.PReLU(), res_scale=1):\n",
    "\n",
    "        super(ResBlock, self).__init__()\n",
    "        m = []\n",
    "        for i in range(2):\n",
    "            m.append(conv(n_feats, n_feats, kernel_size, bias=bias))\n",
    "            if bn:\n",
    "                m.append(nn.BatchNorm2d(n_feats))\n",
    "            if i == 0:\n",
    "                m.append(act)\n",
    "\n",
    "        self.body = nn.Sequential(*m)\n",
    "        self.res_scale = res_scale\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.body(x).mul(self.res_scale)\n",
    "        res += x\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "class Upsampler(nn.Sequential):\n",
    "    def __init__(self, conv, scale, n_feats, bn=False, act=False, bias=True):\n",
    "\n",
    "        m = []\n",
    "        if (scale & (scale - 1)) == 0:  # Is scale = 2^n?\n",
    "            for _ in range(int(math.log(scale, 2))):\n",
    "                m.append(conv(n_feats, 4 * n_feats, 3, bias))\n",
    "                m.append(nn.PixelShuffle(2))\n",
    "                if bn:\n",
    "                    m.append(nn.BatchNorm2d(n_feats))\n",
    "                if act == 'relu':\n",
    "                    m.append(nn.ReLU(True))\n",
    "                elif act == 'prelu':\n",
    "                    m.append(nn.PReLU(n_feats))\n",
    "\n",
    "        elif scale == 3:\n",
    "            m.append(conv(n_feats, 9 * n_feats, 3, bias))\n",
    "            m.append(nn.PixelShuffle(3))\n",
    "            if bn:\n",
    "                m.append(nn.BatchNorm2d(n_feats))\n",
    "            if act == 'relu':\n",
    "                m.append(nn.ReLU(True))\n",
    "            elif act == 'prelu':\n",
    "                m.append(nn.PReLU(n_feats))\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        super(Upsampler, self).__init__(*m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d16d05ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T00:24:41.286179Z",
     "iopub.status.busy": "2023-03-16T00:24:41.285913Z",
     "iopub.status.idle": "2023-03-16T00:24:41.301526Z",
     "shell.execute_reply": "2023-03-16T00:24:41.300549Z"
    },
    "papermill": {
     "duration": 0.023412,
     "end_time": "2023-03-16T00:24:41.303663",
     "exception": false,
     "start_time": "2023-03-16T00:24:41.280251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tools\n",
    "\n",
    "def normalize(x):\n",
    "    return x.mul_(2).add_(-1)\n",
    "\n",
    "def same_padding(images, ksizes, strides, rates):\n",
    "    assert len(images.size()) == 4\n",
    "    batch_size, channel, rows, cols = images.size()\n",
    "    out_rows = (rows + strides[0] - 1) // strides[0]\n",
    "    out_cols = (cols + strides[1] - 1) // strides[1]\n",
    "    effective_k_row = (ksizes[0] - 1) * rates[0] + 1\n",
    "    effective_k_col = (ksizes[1] - 1) * rates[1] + 1\n",
    "    padding_rows = max(0, (out_rows-1)*strides[0]+effective_k_row-rows)\n",
    "    padding_cols = max(0, (out_cols-1)*strides[1]+effective_k_col-cols)\n",
    "    # Pad the input\n",
    "    padding_top = int(padding_rows / 2.)\n",
    "    padding_left = int(padding_cols / 2.)\n",
    "    padding_bottom = padding_rows - padding_top\n",
    "    padding_right = padding_cols - padding_left\n",
    "    paddings = (padding_left, padding_right, padding_top, padding_bottom)\n",
    "    images = torch.nn.ZeroPad2d(paddings)(images)\n",
    "    return images\n",
    "\n",
    "\n",
    "def extract_image_patches(images, ksizes, strides, rates, padding='same'):\n",
    "    \"\"\"\n",
    "    Extract patches from images and put them in the C output dimension.\n",
    "    :param padding:\n",
    "    :param images: [batch, channels, in_rows, in_cols]. A 4-D Tensor with shape\n",
    "    :param ksizes: [ksize_rows, ksize_cols]. The size of the sliding window for\n",
    "     each dimension of images\n",
    "    :param strides: [stride_rows, stride_cols]\n",
    "    :param rates: [dilation_rows, dilation_cols]\n",
    "    :return: A Tensor\n",
    "    \"\"\"\n",
    "    assert len(images.size()) == 4\n",
    "    assert padding in ['same', 'valid']\n",
    "    batch_size, channel, height, width = images.size()\n",
    "    \n",
    "    if padding == 'same':\n",
    "        images = same_padding(images, ksizes, strides, rates)\n",
    "    elif padding == 'valid':\n",
    "        pass\n",
    "    else:\n",
    "        raise NotImplementedError('Unsupported padding type: {}.\\\n",
    "                Only \"same\" or \"valid\" are supported.'.format(padding))\n",
    "\n",
    "    unfold = torch.nn.Unfold(kernel_size=ksizes,\n",
    "                             dilation=rates,\n",
    "                             padding=0,\n",
    "                             stride=strides)\n",
    "    patches = unfold(images)\n",
    "    return patches  # [N, C*k*k, L], L is the total number of such blocks\n",
    "def reduce_mean(x, axis=None, keepdim=False):\n",
    "    if not axis:\n",
    "        axis = range(len(x.shape))\n",
    "    for i in sorted(axis, reverse=True):\n",
    "        x = torch.mean(x, dim=i, keepdim=keepdim)\n",
    "    return x\n",
    "\n",
    "\n",
    "def reduce_std(x, axis=None, keepdim=False):\n",
    "    if not axis:\n",
    "        axis = range(len(x.shape))\n",
    "    for i in sorted(axis, reverse=True):\n",
    "        x = torch.std(x, dim=i, keepdim=keepdim)\n",
    "    return x\n",
    "\n",
    "\n",
    "def reduce_sum(x, axis=None, keepdim=False):\n",
    "    if not axis:\n",
    "        axis = range(len(x.shape))\n",
    "    for i in sorted(axis, reverse=True):\n",
    "        x = torch.sum(x, dim=i, keepdim=keepdim)\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b09c589f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T00:24:41.314745Z",
     "iopub.status.busy": "2023-03-16T00:24:41.314474Z",
     "iopub.status.idle": "2023-03-16T00:24:41.334957Z",
     "shell.execute_reply": "2023-03-16T00:24:41.333919Z"
    },
    "papermill": {
     "duration": 0.028825,
     "end_time": "2023-03-16T00:24:41.336817",
     "exception": false,
     "start_time": "2023-03-16T00:24:41.307992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# attention\n",
    "\n",
    "class PyramidAttention(nn.Module):\n",
    "    def __init__(self, level=5, res_scale=1, channel=64, reduction=2, ksize=3, stride=1, softmax_scale=10, average=True,\n",
    "                 conv=default_conv):\n",
    "        super(PyramidAttention, self).__init__()\n",
    "        self.ksize = ksize\n",
    "        self.stride = stride\n",
    "        self.res_scale = res_scale\n",
    "        self.softmax_scale = softmax_scale\n",
    "        self.scale = [1 - i / 10 for i in range(level)]\n",
    "        self.average = average\n",
    "        escape_NaN = torch.FloatTensor([1e-4])\n",
    "        self.register_buffer('escape_NaN', escape_NaN)\n",
    "        self.conv_match_L_base = BasicBlock(conv, channel, channel // reduction, 1, bn=False, act=nn.PReLU())\n",
    "        self.conv_match = BasicBlock(conv, channel, channel // reduction, 1, bn=False, act=nn.PReLU())\n",
    "        self.conv_assembly = BasicBlock(conv, channel, channel, 1, bn=False, act=nn.PReLU())\n",
    "\n",
    "    def forward(self, input):\n",
    "        res = input\n",
    "        # theta\n",
    "        match_base = self.conv_match_L_base(input)\n",
    "        shape_base = list(res.size())\n",
    "        input_groups = torch.split(match_base, 1, dim=0)\n",
    "        # patch size for matching\n",
    "        kernel = self.ksize\n",
    "        # raw_w is for reconstruction\n",
    "        raw_w = []\n",
    "        # w is for matching\n",
    "        w = []\n",
    "        # build feature pyramid\n",
    "        for i in range(len(self.scale)):\n",
    "            ref = input\n",
    "            if self.scale[i] != 1:\n",
    "                ref = F.interpolate(input, scale_factor=self.scale[i], mode='bicubic')\n",
    "            # feature transformation function f\n",
    "            base = self.conv_assembly(ref)\n",
    "            shape_input = base.shape\n",
    "            # sampling\n",
    "            raw_w_i = extract_image_patches(base, ksizes=[kernel, kernel],\n",
    "                                            strides=[self.stride, self.stride],\n",
    "                                            rates=[1, 1],\n",
    "                                            padding='same')  # [N, C*k*k, L]\n",
    "            raw_w_i = raw_w_i.view(shape_input[0], shape_input[1], kernel, kernel, -1)\n",
    "            raw_w_i = raw_w_i.permute(0, 4, 1, 2, 3)  # raw_shape: [N, L, C, k, k]\n",
    "            raw_w_i_groups = torch.split(raw_w_i, 1, dim=0)\n",
    "            raw_w.append(raw_w_i_groups)\n",
    "\n",
    "            # feature transformation function g\n",
    "            ref_i = self.conv_match(ref)\n",
    "            shape_ref = ref_i.shape\n",
    "            # sampling\n",
    "            w_i = extract_image_patches(ref_i, ksizes=[self.ksize, self.ksize],\n",
    "                                        strides=[self.stride, self.stride],\n",
    "                                        rates=[1, 1],\n",
    "                                        padding='same')\n",
    "            w_i = w_i.view(shape_ref[0], shape_ref[1], self.ksize, self.ksize, -1)\n",
    "            w_i = w_i.permute(0, 4, 1, 2, 3)  # w shape: [N, L, C, k, k]\n",
    "            w_i_groups = torch.split(w_i, 1, dim=0)\n",
    "            w.append(w_i_groups)\n",
    "\n",
    "        y = []\n",
    "        for idx, xi in enumerate(input_groups):\n",
    "            # group in a filter\n",
    "            wi = torch.cat([w[i][idx][0] for i in range(len(self.scale))], dim=0)  # [L, C, k, k]\n",
    "            # normalize\n",
    "            max_wi = torch.max(torch.sqrt(reduce_sum(torch.pow(wi, 2),\n",
    "                                                     axis=[1, 2, 3],\n",
    "                                                     keepdim=True)),\n",
    "                               self.escape_NaN)\n",
    "            wi_normed = wi / max_wi\n",
    "            # matching\n",
    "            xi = same_padding(xi, [self.ksize, self.ksize], [1, 1], [1, 1])  # xi: 1*c*H*W\n",
    "            yi = F.conv2d(xi, wi_normed, stride=1)  # [1, L, H, W] L = shape_ref[2]*shape_ref[3]\n",
    "            yi = yi.view(1, wi.shape[0], shape_base[2], shape_base[3])  # (B=1, C=32*32, H=32, W=32)\n",
    "            # softmax matching score\n",
    "            yi = F.softmax(yi * self.softmax_scale, dim=1)\n",
    "\n",
    "            if not self.average:\n",
    "                yi = (yi == yi.max(dim=1, keepdim=True)[0]).float()\n",
    "\n",
    "            # deconv for patch pasting\n",
    "            raw_wi = torch.cat([raw_w[i][idx][0] for i in range(len(self.scale))], dim=0)\n",
    "            yi = F.conv_transpose2d(yi, raw_wi, stride=self.stride, padding=1) / 4.\n",
    "            y.append(yi)\n",
    "\n",
    "        y = torch.cat(y, dim=0) + res * self.res_scale  # back to the mini-batch\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31471a87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T00:24:41.347240Z",
     "iopub.status.busy": "2023-03-16T00:24:41.346971Z",
     "iopub.status.idle": "2023-03-16T00:24:41.361187Z",
     "shell.execute_reply": "2023-03-16T00:24:41.360102Z"
    },
    "papermill": {
     "duration": 0.021699,
     "end_time": "2023-03-16T00:24:41.363377",
     "exception": false,
     "start_time": "2023-03-16T00:24:41.341678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#panet\n",
    "\n",
    "def make_model():\n",
    "    return PANET()\n",
    "\n",
    "class PANET(nn.Module):\n",
    "    def __init__(self, conv=default_conv):\n",
    "        super(PANET, self).__init__()\n",
    "\n",
    "        n_resblocks = 10\n",
    "        res_scale = 1\n",
    "        n_feats = 64\n",
    "        kernel_size = 3\n",
    "        n_colors = 3\n",
    "\n",
    "        rgb_range = 1\n",
    "        rgb_mean = (0.4488, 0.4371, 0.4040)\n",
    "        rgb_std = (1.0, 1.0, 1.0)\n",
    "        self.sub_mean = MeanShift(rgb_range, rgb_mean, rgb_std)\n",
    "        msa = PyramidAttention()\n",
    "        # define head module\n",
    "        m_head = [conv(n_colors, n_feats, kernel_size)]\n",
    "\n",
    "        # define body module\n",
    "        m_body = [\n",
    "            ResBlock(\n",
    "                conv, n_feats, kernel_size, nn.PReLU(), res_scale=res_scale\n",
    "            ) for _ in range(n_resblocks // 2)\n",
    "        ]\n",
    "        m_body.append(msa)\n",
    "        for i in range(n_resblocks // 2):\n",
    "            m_body.append(ResBlock(conv, n_feats, kernel_size, nn.PReLU(), res_scale=res_scale))\n",
    "\n",
    "        m_body.append(conv(n_feats, n_feats, kernel_size))\n",
    "\n",
    "        # define tail module\n",
    "        # m_tail = [\n",
    "        #    common.Upsampler(conv, scale, n_feats, act=False),\n",
    "        #    conv(n_feats, args.n_colors, kernel_size)\n",
    "        # ]\n",
    "        m_tail = [\n",
    "            conv(n_feats, n_colors, kernel_size)\n",
    "        ]\n",
    "\n",
    "        self.add_mean = MeanShift(rgb_range, rgb_mean, rgb_std, 1)\n",
    "\n",
    "        self.head = nn.Sequential(*m_head)\n",
    "        self.body = nn.Sequential(*m_body)\n",
    "        self.tail = nn.Sequential(*m_tail)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.sub_mean(x)\n",
    "        x = self.head(x)\n",
    "\n",
    "        res = self.body(x)\n",
    "\n",
    "        res += x\n",
    "\n",
    "        x = self.tail(res)\n",
    "        # x = self.add_mean(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def load_state_dict(self, state_dict, strict=True):\n",
    "        own_state = self.state_dict()\n",
    "        for name, param in state_dict.items():\n",
    "            if name in own_state:\n",
    "                if isinstance(param, nn.Parameter):\n",
    "                    param = param.data\n",
    "                try:\n",
    "                    own_state[name].copy_(param)\n",
    "                except Exception:\n",
    "                    if name.find('tail') == -1:\n",
    "                        raise RuntimeError('While copying the parameter named {}, '\n",
    "                                           'whose dimensions in the model are {} and '\n",
    "                                           'whose dimensions in the checkpoint are {}.'\n",
    "                                           .format(name, own_state[name].size(), param.size()))\n",
    "            elif strict:\n",
    "                if name.find('tail') == -1:\n",
    "                    raise KeyError('unexpected key \"{}\" in state_dict'\n",
    "                                   .format(name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b36b93d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T00:24:41.373427Z",
     "iopub.status.busy": "2023-03-16T00:24:41.373160Z",
     "iopub.status.idle": "2023-03-16T00:24:43.954165Z",
     "shell.execute_reply": "2023-03-16T00:24:43.953200Z"
    },
    "papermill": {
     "duration": 2.588848,
     "end_time": "2023-03-16T00:24:43.956555",
     "exception": false,
     "start_time": "2023-03-16T00:24:41.367707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = PANET().cuda()\n",
    "loss_func = nn.MSELoss()\n",
    "best_train_loss = float('inf')\n",
    "best_val_loss = float('inf')\n",
    "lr = 1e-4\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=1e-4)\n",
    "train_dataloader = trainloader1\n",
    "val_dataloader = valloader\n",
    "test_dataloader = testloader\n",
    "epochs = train_number_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d183dd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T00:24:43.968047Z",
     "iopub.status.busy": "2023-03-16T00:24:43.967369Z",
     "iopub.status.idle": "2023-03-16T00:24:43.985387Z",
     "shell.execute_reply": "2023-03-16T00:24:43.984553Z"
    },
    "papermill": {
     "duration": 0.026031,
     "end_time": "2023-03-16T00:24:43.987445",
     "exception": false,
     "start_time": "2023-03-16T00:24:43.961414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Pre_train(trainloader, valloader, model, loss_func, optimizer):\n",
    "    global best_train_loss\n",
    "    global best_val_loss\n",
    "    device = torch.device('cuda')\n",
    "    model = model.to(device)\n",
    "    for epoch in range(0, epochs):\n",
    "        # train part\n",
    "        total_train_loss = 0\n",
    "        counter1 = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            input_pic, label = data\n",
    "            #转移到GPU上，类型变为float以与模型参数类型匹配\n",
    "            input_pic, label = input_pic.to(device, dtype=torch.float), label.to(device, dtype=torch.float)\n",
    "            \n",
    "            \n",
    "            # output 已经双线性插值 进网络重建，得到三通道图片\n",
    "            output = model(input_pic)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss = loss_func(output, label)\n",
    "            loss.requires_grad_(True)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "            counter1 += 1\n",
    "\n",
    "        # val part\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        \n",
    "        #初始化三通道PSNR值与CPSNR值\n",
    "        total_psnr_r = 0\n",
    "        total_psnr_g = 0\n",
    "        total_psnr_b = 0\n",
    "        total_cpsnr = 0\n",
    "        \n",
    "        counter2 = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for j, data2 in enumerate(valloader, 0):\n",
    "                input_pic2, label2 = data2\n",
    "                \n",
    "                #CFA滤波与双线性插值的过程已在val_data_get函数中完成\n",
    "                input_pic2, label2 = input_pic2.to(device, dtype=torch.float), label2.to(device, dtype=torch.float)\n",
    "                # 进网络\n",
    "                \n",
    "                output2 = model(input_pic2)\n",
    "                \n",
    "                # RGGB采样\n",
    "                output2 = output2.cuda()\n",
    "                \n",
    "                loss2 = loss_func(output2, label2)\n",
    "                \n",
    "                total_val_loss += loss2.item()\n",
    "                \n",
    "                #为计算PSNR部分而进行MSE的计算\n",
    "                \n",
    "                #RGB三通道的MSE值\n",
    "                \n",
    "                mse_r = loss_func(output2[:, 0, :, :],\n",
    "                                 label2[:, 0, :, :])\n",
    "                mse_g = loss_func(output2[:, 1, :, :],\n",
    "                                 label2[:, 1, :, :])\n",
    "                mse_b = loss_func(output2[:, 2, :, :],\n",
    "                                 label2[:, 2, :, :])\n",
    "                #CPSNR，即三通道PSNR值的平均值\n",
    "                cmse = loss_func(output2[:, :, :, :],\n",
    "                                 label2[:, :, :, :])\n",
    "                \n",
    "                #计算所有图片RGB三通道的PSNR值及CPSNR之和\n",
    "                if mse_r.item() < 1.0e-10:  # 均方误差小到过分了\n",
    "                    total_psnr_r += 100\n",
    "                else:\n",
    "                    total_psnr_r += 20 * math.log10(1 / math.sqrt(mse_r.item()))\n",
    "                \n",
    "                if mse_g.item() < 1.0e-10:  # 均方误差小到过分了\n",
    "                    total_psnr_g += 100\n",
    "                else:\n",
    "                    total_psnr_g += 20 * math.log10(1 / math.sqrt(mse_g.item()))\n",
    "                \n",
    "                if mse_b.item() < 1.0e-10:  # 均方误差小到过分了\n",
    "                    total_psnr_b += 100\n",
    "                else:\n",
    "                    total_psnr_b += 20 * math.log10(1 / math.sqrt(mse_b.item()))\n",
    "                \n",
    "                if cmse.item() < 1.0e-10:  # 均方误差小到过分了\n",
    "                    total_cpsnr += 100\n",
    "                else:\n",
    "                    total_cpsnr += 20 * math.log10(1 / math.sqrt(cmse.item()))\n",
    "            \n",
    "                counter2 += 1\n",
    "        \n",
    "                \n",
    "            train_loss_avg = total_train_loss / counter1\n",
    "            val_loss_avg = total_val_loss / counter2\n",
    "            \n",
    "            #计算所有图片RGB三通道的PSNR值及CPSNR之均值\n",
    "            psnr_r_avg = total_psnr_r / counter2\n",
    "            psnr_g_avg = total_psnr_g / counter2\n",
    "            psnr_b_avg = total_psnr_b / counter2\n",
    "            cpsnr_avg = total_cpsnr / counter2\n",
    "            \n",
    "            print(\"Epoch number: {} , Train loss: {:.4f}, Val loss: {:.4f}, \\nPSNR_R: {:.4f}, PSNR_G: {:.4f}, PSNR_B: {:.4f}, CPSNR: {:.4f}\\n\".format(epoch, train_loss_avg, val_loss_avg, psnr_r_avg, psnr_g_avg, psnr_b_avg, cpsnr_avg))        \n",
    "\n",
    "        if val_loss_avg < best_val_loss:\n",
    "            best_val_loss = val_loss_avg\n",
    "            torch.save(net.state_dict(), '/kaggle/working/best_pretrain_panet.pth')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38adb4ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T00:24:43.997955Z",
     "iopub.status.busy": "2023-03-16T00:24:43.997639Z",
     "iopub.status.idle": "2023-03-16T00:24:44.090275Z",
     "shell.execute_reply": "2023-03-16T00:24:44.089368Z"
    },
    "papermill": {
     "duration": 0.100558,
     "end_time": "2023-03-16T00:24:44.092660",
     "exception": false,
     "start_time": "2023-03-16T00:24:43.992102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To restore Panet to the last checkpoint\n",
    "net.load_state_dict(torch.load('/kaggle/input/best-pretrain-panet-3epoch/best_pretrain_panet_3epoch.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "131c1fc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T00:24:44.103449Z",
     "iopub.status.busy": "2023-03-16T00:24:44.102800Z",
     "iopub.status.idle": "2023-03-16T06:08:45.821905Z",
     "shell.execute_reply": "2023-03-16T06:08:45.820897Z"
    },
    "papermill": {
     "duration": 20641.733097,
     "end_time": "2023-03-16T06:08:45.830375",
     "exception": false,
     "start_time": "2023-03-16T00:24:44.097278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 0 , Train loss: 0.0011, Val loss: 0.0014, \n",
      "PSNR_R: 29.2178, PSNR_G: 33.1509, PSNR_B: 29.5872, CPSNR: 30.1326\n",
      "\n",
      "Epoch number: 1 , Train loss: 0.0012, Val loss: 0.0014, \n",
      "PSNR_R: 29.2142, PSNR_G: 31.8072, PSNR_B: 29.5512, CPSNR: 29.8695\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Pre_train(train_dataloader,val_dataloader, net, loss_func, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "695961ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T06:08:45.842912Z",
     "iopub.status.busy": "2023-03-16T06:08:45.842604Z",
     "iopub.status.idle": "2023-03-16T06:08:45.861826Z",
     "shell.execute_reply": "2023-03-16T06:08:45.858021Z"
    },
    "papermill": {
     "duration": 0.02729,
     "end_time": "2023-03-16T06:08:45.863926",
     "exception": false,
     "start_time": "2023-03-16T06:08:45.836636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Pre_test(testloader, model, loss_func):\n",
    "    global best_test_loss\n",
    "    device = torch.device('cuda')\n",
    "    model = model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    total_test_loss = 0\n",
    "\n",
    "    #初始化三通道PSNR值与CPSNR值\n",
    "    total_psnr_r = 0\n",
    "    total_psnr_g = 0\n",
    "    total_psnr_b = 0\n",
    "    total_cpsnr = 0\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for j, data in enumerate(testloader, 0):\n",
    "            input_pic, label = data\n",
    "\n",
    "            #CFA滤波与双线性插值的过程已在Gehler_Shi_test_data_get函数中完成\n",
    "            input_pic, label = input_pic.to(device, dtype=torch.float), label.to(device, dtype=torch.float)\n",
    "            # 进网络\n",
    "\n",
    "            output = model(input_pic)\n",
    "\n",
    "            # RGGB采样\n",
    "            output = output.cuda()\n",
    "\n",
    "            loss = loss_func(output, label)\n",
    "\n",
    "            total_test_loss += loss.item()\n",
    "\n",
    "            #为计算PSNR部分而进行MSE的计算\n",
    "\n",
    "            #设置去除边界的宽度\n",
    "            bound = 1\n",
    "\n",
    "            #RGB三通道的MSE值\n",
    "\n",
    "            mse_r = loss_func(output[:, 0, bound:-bound,bound:-bound],\n",
    "                             label[:, 0, bound:-bound,bound:-bound])\n",
    "            mse_g = loss_func(output[:, 1, bound:-bound,bound:-bound],\n",
    "                             label[:, 1, bound:-bound,bound:-bound])\n",
    "            mse_b = loss_func(output[:, 2, bound:-bound,bound:-bound],\n",
    "                             label[:, 2, bound:-bound,bound:-bound])\n",
    "            #CPSNR，即三通道PSNR值的平均值\n",
    "            cmse = loss_func(output[:, :, bound:-bound,bound:-bound],\n",
    "                             label[:, :, bound:-bound,bound:-bound])\n",
    "\n",
    "            #计算所有图片RGB三通道的PSNR值及CPSNR之和\n",
    "            if mse_r.item() < 1.0e-10:  # 均方误差小到过分了\n",
    "                total_psnr_r += 100\n",
    "            else:\n",
    "                total_psnr_r += 20 * math.log10(1 / math.sqrt(mse_r.item()))\n",
    "\n",
    "            if mse_g.item() < 1.0e-10:  # 均方误差小到过分了\n",
    "                total_psnr_g += 100\n",
    "            else:\n",
    "                total_psnr_g += 20 * math.log10(1 / math.sqrt(mse_g.item()))\n",
    "\n",
    "            if mse_b.item() < 1.0e-10:  # 均方误差小到过分了\n",
    "                total_psnr_b += 100\n",
    "            else:\n",
    "                total_psnr_b += 20 * math.log10(1 / math.sqrt(mse_b.item()))\n",
    "\n",
    "            if cmse.item() < 1.0e-10:  # 均方误差小到过分了\n",
    "                total_cpsnr += 100\n",
    "            else:\n",
    "                total_cpsnr += 20 * math.log10(1 / math.sqrt(cmse.item()))\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "        test_loss_avg = total_test_loss / counter\n",
    "\n",
    "        #计算所有图片RGB三通道的PSNR值及CPSNR之均值\n",
    "        psnr_r_avg = total_psnr_r / counter\n",
    "        psnr_g_avg = total_psnr_g / counter\n",
    "        psnr_b_avg = total_psnr_b / counter\n",
    "        cpsnr_avg = total_cpsnr / counter\n",
    "\n",
    "        print(\"Test loss: {:.4f}, \\nPSNR_R: {:.4f}, PSNR_G: {:.4f}, PSNR_B: {:.4f}, CPSNR: {:.4f}\\n\".format(test_loss_avg, psnr_r_avg, psnr_g_avg, psnr_b_avg, cpsnr_avg))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb69cebc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T06:08:45.876920Z",
     "iopub.status.busy": "2023-03-16T06:08:45.876582Z",
     "iopub.status.idle": "2023-03-16T06:19:48.100456Z",
     "shell.execute_reply": "2023-03-16T06:19:48.098807Z"
    },
    "papermill": {
     "duration": 662.238502,
     "end_time": "2023-03-16T06:19:48.109456",
     "exception": false,
     "start_time": "2023-03-16T06:08:45.870954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0001, \n",
      "PSNR_R: 42.4004, PSNR_G: 39.8077, PSNR_B: 42.6564, CPSNR: 41.4118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Pre_test(test_dataloader, net, loss_func)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21513.629803,
   "end_time": "2023-03-16T06:19:51.586078",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-16T00:21:17.956275",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
