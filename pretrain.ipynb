{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c4abca5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-18T13:56:33.786612Z",
     "iopub.status.busy": "2023-03-18T13:56:33.786063Z",
     "iopub.status.idle": "2023-03-18T13:56:36.973405Z",
     "shell.execute_reply": "2023-03-18T13:56:36.972466Z"
    },
    "papermill": {
     "duration": 3.196024,
     "end_time": "2023-03-18T13:56:36.975877",
     "exception": false,
     "start_time": "2023-03-18T13:56:33.779853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import gc\n",
    "import math\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d94edb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T13:56:36.985910Z",
     "iopub.status.busy": "2023-03-18T13:56:36.985402Z",
     "iopub.status.idle": "2023-03-18T13:56:36.991564Z",
     "shell.execute_reply": "2023-03-18T13:56:36.990678Z"
    },
    "papermill": {
     "duration": 0.012136,
     "end_time": "2023-03-18T13:56:36.993490",
     "exception": false,
     "start_time": "2023-03-18T13:56:36.981354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"kaggle/working/model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8ccbd6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T13:56:37.001347Z",
     "iopub.status.busy": "2023-03-18T13:56:37.000587Z",
     "iopub.status.idle": "2023-03-18T13:56:37.007262Z",
     "shell.execute_reply": "2023-03-18T13:56:37.006349Z"
    },
    "papermill": {
     "duration": 0.012573,
     "end_time": "2023-03-18T13:56:37.009273",
     "exception": false,
     "start_time": "2023-03-18T13:56:36.996700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def CFA(pic: np.ndarray):\n",
    "    #h, w -> height,width(cv2-format)\n",
    "    h, w, _ = pic.shape\n",
    "    RGGB = np.array([[[1, 0, 0], [0, 1, 0]], [[0, 1, 0], [0, 0, 1]]])\n",
    "    #模板平铺的倍数\n",
    "    time_h = int(np.ceil(h / 2))\n",
    "    time_w = int(np.ceil(w / 2))\n",
    "    #平铺模板\n",
    "    CFA = np.tile(RGGB, (time_h, time_w, 1))\n",
    "    CFA = CFA[:h, :w, :]\n",
    "    #CFA模板滤波\n",
    "    processed = pic * CFA\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c715c610",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T13:56:37.017591Z",
     "iopub.status.busy": "2023-03-18T13:56:37.016201Z",
     "iopub.status.idle": "2023-03-18T13:56:37.027447Z",
     "shell.execute_reply": "2023-03-18T13:56:37.026477Z"
    },
    "papermill": {
     "duration": 0.01743,
     "end_time": "2023-03-18T13:56:37.029651",
     "exception": false,
     "start_time": "2023-03-18T13:56:37.012221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#对四维Tensor进行CFA滤波，pattern为滤波模式字符串（RGGB, BGGR等）\n",
    "def CFA_d4(pic: torch.Tensor, pattern: str):\n",
    "    #b, c, h, w -> batch_size, channel, height, width\n",
    "    b, c, h, w = pic.shape\n",
    "    pic = pic.cuda()\n",
    "    \n",
    "    processed = torch.zeros(pic.shape)\n",
    "    processed = processed.cuda()\n",
    "    \n",
    "    RGGB = np.array([[[1, 0, 0], [0, 1, 0]], [[0, 1, 0], [0, 0, 1]]])\n",
    "    \n",
    "    #模板平铺的倍数\n",
    "    time_h = int(np.ceil(h / 2))\n",
    "    time_w = int(np.ceil(w / 2))\n",
    "    \n",
    "    #tiled RGGB\n",
    "    CFA = np.tile(RGGB, (time_h, time_w, 1))\n",
    "    processed2 = torch.clone(pic)\n",
    "    processed2 = processed2.cuda()\n",
    "   \n",
    "    CFA = CFA[:h, :w, :]\n",
    "    #CFA -> h*w*3,RGB\n",
    "    CFA3 = CFA.transpose((2,0,1))\n",
    "    #CFA3 -> 3*h*w,RGB\n",
    "    # numpy 转 tensor\n",
    "    CFA3 = torch.from_numpy(CFA3)\n",
    "    CFA3 = CFA3.cuda()\n",
    "    \n",
    "    for i in range(b):\n",
    "        if pattern == \"BGGR\":\n",
    "            #translate BGGR -> RGGB\n",
    "            processed2[i] = torch.roll(processed2[i],shifts=(-1, -1), dims = (1,2))\n",
    "        elif pattern == \"GBRG\":\n",
    "            #translate GBRG -> RGGB\n",
    "            processed2[i] = torch.roll(processed2[i],shifts=(-1, 0), dims = (1,2))\n",
    "        elif pattern == \"GRBG\":\n",
    "            #translate GRBG -> RGGB\n",
    "            processed2[i] = torch.roll(processed2[i],shifts=(0, -1), dims = (1,2))\n",
    "    for i in range(b):\n",
    "        processed2[i] = processed2[i] * CFA3\n",
    "        \n",
    "    return processed2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d25c831e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T13:56:37.037042Z",
     "iopub.status.busy": "2023-03-18T13:56:37.036763Z",
     "iopub.status.idle": "2023-03-18T13:56:37.051714Z",
     "shell.execute_reply": "2023-03-18T13:56:37.050853Z"
    },
    "papermill": {
     "duration": 0.020934,
     "end_time": "2023-03-18T13:56:37.053712",
     "exception": false,
     "start_time": "2023-03-18T13:56:37.032778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# img_o为输入，fil为卷积核，进行卷积，实现双线性插值\n",
    "def my_fil(pic):\n",
    "    h, w, _ = pic.shape\n",
    "    #RGB -> BGR, to split\n",
    "    pic = pic[:,:,::-1]\n",
    "    #解决内存不连续问题\n",
    "    pic = pic.copy()\n",
    "    [B, G, R] = cv2.split(pic)\n",
    "    filter = np.array([[[0.25, 0., 0.25],\n",
    "                        [0.5, 0.25, 0.5],\n",
    "                        [0.25, 0., 0.25]],\n",
    "\n",
    "                       [[0.5, 0.25, 0.5],\n",
    "                        [1., 1., 1.],\n",
    "                        [0.5, 0.25, 0.5]],\n",
    "\n",
    "                       [[0.25, 0., 0.25],\n",
    "                        [0.5, 0.25, 0.5],\n",
    "                        [0.25, 0., 0.25]]])\n",
    "\n",
    "    B_fil = cv2.filter2D(B, -1, kernel=filter[:, :, 2])\n",
    "    G_fil = cv2.filter2D(G, -1, kernel=filter[:, :, 1])\n",
    "    R_fil = cv2.filter2D(R, -1, kernel=filter[:, :, 0])\n",
    "\n",
    "    pic_new = cv2.merge([B_fil, G_fil, R_fil])\n",
    "    #BGR -> RGB\n",
    "    pic_new = pic_new[:,:,::-1]\n",
    "    #解决内存不连续问题\n",
    "    pic_new = pic_new.copy()\n",
    "    return pic_new\n",
    "\n",
    "def my_fil_d4(pic):\n",
    "    #b, c, h, w -> batch_size, channel, height, width\n",
    "    b, c, h, w = pic.shape\n",
    "    filter = np.array([[[0.25, 0., 0.25],\n",
    "                        [0.5, 0.25, 0.5],\n",
    "                        [0.25, 0., 0.25]],\n",
    "\n",
    "                       [[0.5, 0.25, 0.5],\n",
    "                        [1., 1., 1.],\n",
    "                        [0.5, 0.25, 0.5]],\n",
    "\n",
    "                       [[0.25, 0., 0.25],\n",
    "                        [0.5, 0.25, 0.5],\n",
    "                        [0.25, 0., 0.25]]])\n",
    "    \n",
    "    # pic转numpy\n",
    "    pic = pic.detach().cpu().numpy() if pic.requires_grad else pic.cpu().numpy()\n",
    "    pic3 = pic\n",
    "    for i in range(b):\n",
    "        pic2 = pic[i]\n",
    "        #CHW -> HWC, to split\n",
    "        pic2 = pic2.transpose((1, 2, 0))\n",
    "        #RGB -> BGR, to split\n",
    "        pic2 = pic2[:,:,::-1]\n",
    "        #解决内存不连续问题\n",
    "        pic2 = pic2.copy()\n",
    "        \n",
    "        [B, G, R] = cv2.split(pic2)\n",
    "        \n",
    "        B_fil = cv2.filter2D(B, -1, kernel=filter[:, :, 2])\n",
    "        G_fil = cv2.filter2D(G, -1, kernel=filter[:, :, 1])\n",
    "        R_fil = cv2.filter2D(R, -1, kernel=filter[:, :, 0])\n",
    "        \n",
    "        pic_new = cv2.merge([B_fil, G_fil, R_fil])\n",
    "        #BGR -> RGB\n",
    "        pic_new = pic_new[:,:,::-1]\n",
    "        #解决内存不连续问题\n",
    "        pic_new = pic_new.copy()\n",
    "        #HWC -> CHW\n",
    "        pic_new = pic_new.transpose((2, 0, 1))\n",
    "        pic3[i] = pic_new\n",
    "    pic3 = torch.from_numpy(pic3)\n",
    "    pic3 = pic3.cuda()\n",
    "    return pic3\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60de0130",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T13:56:37.060952Z",
     "iopub.status.busy": "2023-03-18T13:56:37.060671Z",
     "iopub.status.idle": "2023-03-18T13:56:37.069687Z",
     "shell.execute_reply": "2023-03-18T13:56:37.068826Z"
    },
    "papermill": {
     "duration": 0.014877,
     "end_time": "2023-03-18T13:56:37.071703",
     "exception": false,
     "start_time": "2023-03-18T13:56:37.056826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, filepath, transform=None):\n",
    "        self.filepath = filepath\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        imgs = os.listdir(filepath)\n",
    "        path = filepath + imgs[index]\n",
    "        \n",
    "        temp = cv2.imread(path)\n",
    "        #BGR -> RGB\n",
    "        temp = temp[:,:,::-1]\n",
    "        #解决内存不连续问题\n",
    "        temp = temp.copy()\n",
    "        temp = np.float64(temp)\n",
    "        h, w, _ = temp.shape\n",
    "\n",
    "        temp = temp[0:(h - h%16), 0:(w-w%16), :]  # 避免上下采样时出现维度不匹配问题\n",
    "\n",
    "        #归一化\n",
    "        temp = temp / 255.0\n",
    "        \n",
    "        label = temp\n",
    "        data = my_fil(CFA(temp))\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            data = self.transform(data)\n",
    "            label = self.transform(label)\n",
    "            \n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10c44c20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T13:56:37.079463Z",
     "iopub.status.busy": "2023-03-18T13:56:37.079127Z",
     "iopub.status.idle": "2023-03-18T13:56:37.094425Z",
     "shell.execute_reply": "2023-03-18T13:56:37.093562Z"
    },
    "papermill": {
     "duration": 0.021615,
     "end_time": "2023-03-18T13:56:37.096428",
     "exception": false,
     "start_time": "2023-03-18T13:56:37.074813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_data_get(data_path):\n",
    "    img_list = []\n",
    "    labels = []\n",
    "    imgs = os.listdir(data_path)\n",
    "\n",
    "    for i in range(len(imgs)):\n",
    "        path = data_path + imgs[i]\n",
    "        temp = cv2.imread(path)\n",
    "        #BGR -> RGB\n",
    "        temp = temp[:,:,::-1]\n",
    "        #解决内存不连续问题\n",
    "        temp = temp.copy()\n",
    "        temp = np.float64(temp)\n",
    "        h, w, _ = temp.shape\n",
    "\n",
    "        temp = temp[0:(h - h%16), 0:(w-w%16), :]  # 避免上下采样时出现维度不匹配问题\n",
    "\n",
    "        #归一化\n",
    "        temp = temp / 255.0\n",
    "        \n",
    "        temp_label = temp\n",
    "        temp = CFA(temp)\n",
    "        temp = my_fil(temp)\n",
    "        \n",
    "        img_list.append(temp)\n",
    "        labels.append(temp_label)\n",
    "\n",
    "    train_list, train_label = img_list, labels\n",
    "    print(\"Train data get complete.\")\n",
    "    return train_list, train_label\n",
    "\n",
    "def val_data_get(data_path):\n",
    "    img_list = []\n",
    "    labels = []\n",
    "    imgs = os.listdir(data_path)\n",
    "\n",
    "    for i in range(len(imgs)):\n",
    "        path = data_path + imgs[i]\n",
    "        temp = cv2.imread(path)\n",
    "        #BGR -> RGB\n",
    "        temp = temp[:,:,::-1]\n",
    "        #解决内存不连续问题\n",
    "        temp = temp.copy()\n",
    "        temp = np.float64(temp)\n",
    "        h, w, _ = temp.shape\n",
    "\n",
    "        temp = temp[0:(h - h%16), 0:(w-w%16), :]  # 避免上下采样时出现维度不匹配问题\n",
    "        \n",
    "        #归一化\n",
    "        temp = temp / 255.0\n",
    "        \n",
    "        temp_label = temp\n",
    "        temp = CFA(temp)\n",
    "        temp = my_fil(temp)\n",
    "        \n",
    "        img_list.append(temp)\n",
    "        labels.append(temp_label)\n",
    "        \n",
    "    val_list, val_label = img_list, labels\n",
    "    print(\"Validation data get complete.\")\n",
    "    return val_list, val_label\n",
    "\n",
    "def Gehler_Shi_test_data_get(data_path):\n",
    "    img_list = []\n",
    "    labels = []\n",
    "    imgs = os.listdir(data_path)\n",
    "\n",
    "    for i in range(len(imgs)):\n",
    "        path = data_path + imgs[i]\n",
    "        temp = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "        #BGR -> RGB\n",
    "        temp = temp[:,:,::-1]\n",
    "        #解决内存不连续问题\n",
    "        temp = temp.copy()\n",
    "        temp = np.float64(temp)\n",
    "\n",
    "        # 去除black level(对于CANON5D的图片)\n",
    "        h, w, _ = temp.shape\n",
    "        if h == 2193 or h == 1460:\n",
    "            temp = np.maximum(0., temp - 129.)\n",
    "\n",
    "        temp = temp / 4095.  # 归一化(参考代码中是除以最大值，或许可以考虑除以4095)\n",
    "        h, w, _ = temp.shape\n",
    "\n",
    "        #对Gehler_Shi测试集不进行切分\n",
    "        #将图像的大小缩小为16的倍数以适应UNET\n",
    "        #为了让数据大小统一，切一个统一的大小（设为1344*1344）\n",
    "        temp = temp[0:1344, 0:1344, :]\n",
    "        \n",
    "        #label为原值，input经过CFA滤波并双线性插值\n",
    "        temp_label = temp\n",
    "        temp = np.float64(CFA(temp))\n",
    "        temp = my_fil(temp)\n",
    "\n",
    "        img_list.append(temp)\n",
    "        labels.append(temp_label)\n",
    "\n",
    "    test_list, test_label = img_list, labels\n",
    "    print(\"Gehler-Shi test data get complete.\")\n",
    "    return test_list, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d201425a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T13:56:37.104074Z",
     "iopub.status.busy": "2023-03-18T13:56:37.103779Z",
     "iopub.status.idle": "2023-03-18T13:56:37.317245Z",
     "shell.execute_reply": "2023-03-18T13:56:37.316260Z"
    },
    "papermill": {
     "duration": 0.220044,
     "end_time": "2023-03-18T13:56:37.319616",
     "exception": false,
     "start_time": "2023-03-18T13:56:37.099572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyDataset Correct\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_batch_size = 16\n",
    "train_number_epoch = 50\n",
    "\n",
    "train_dir1 = \"/kaggle/input/div2k-dataset/DIV2K_train_HR/DIV2K_train_HR/\"\n",
    "val_dir = \"/kaggle/input/div2k-dataset/DIV2K_valid_HR/DIV2K_valid_HR/\"\n",
    "#test_dir = \"/kaggle/input/gehler-shi-test/\"\n",
    "\n",
    "#train_list1, train_label1 = train_data_get(train_dir1)\n",
    "#val_list, val_label = val_data_get(val_dir)\n",
    "#test_list, test_label = Gehler_Shi_test_data_get(val_dir)\n",
    "\n",
    "trainset1 = MyDataset(train_dir1, transform=transform)\n",
    "print(\"MyDataset Correct\")\n",
    "trainloader1 = DataLoader(trainset1, batch_size=train_batch_size, shuffle=True)\n",
    "valset = MyDataset(val_dir, transform=transform)\n",
    "valloader = DataLoader(valset, batch_size=1, shuffle=True)\n",
    "#testset = Datasets(data=test_list, label=test_label, transform=transform)\n",
    "#testloader = DataLoader(testset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c361be9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T13:56:37.327663Z",
     "iopub.status.busy": "2023-03-18T13:56:37.327317Z",
     "iopub.status.idle": "2023-03-18T13:56:37.343831Z",
     "shell.execute_reply": "2023-03-18T13:56:37.342809Z"
    },
    "papermill": {
     "duration": 0.022818,
     "end_time": "2023-03-18T13:56:37.345875",
     "exception": false,
     "start_time": "2023-03-18T13:56:37.323057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 基本卷积块\n",
    "class Conv(nn.Module):\n",
    "    def __init__(self, C_in, C_out):\n",
    "        super(Conv, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(C_in, C_out, 3, 1, 1),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(C_out, C_out, 3, 1, 1),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "\n",
    "# 下采样模块\n",
    "class DownSampling(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super(DownSampling, self).__init__()\n",
    "        self.Down = nn.Sequential(\n",
    "            # 使用卷积进行2倍的下采样，通道数不变\n",
    "            nn.Conv2d(C, C, 3, 2, 1),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.Down(x)\n",
    "\n",
    "\n",
    "# 上采样模块\n",
    "class UpSampling(nn.Module):\n",
    "\n",
    "    def __init__(self, C):\n",
    "        super(UpSampling, self).__init__()\n",
    "        # 特征图大小扩大2倍，通道数减半\n",
    "        self.Up = nn.Conv2d(C, C // 2, 1, 1)\n",
    "\n",
    "    def forward(self, x, r):\n",
    "        # 使用邻近插值进行上采样\n",
    "        up = F.interpolate(x, scale_factor=2, mode=\"nearest\")\n",
    "        x = self.Up(up)\n",
    "        # 拼接，当前上采样的，和之前下采样过程中的\n",
    "        return torch.cat((x, r), 1)\n",
    "\n",
    "\n",
    "# 主干网络\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        self.C1 = Conv(3, 64)\n",
    "        self.D1 = DownSampling(64)\n",
    "        self.C2 = Conv(64, 128)\n",
    "        self.D2 = DownSampling(128)\n",
    "        self.C3 = Conv(128, 256)\n",
    "        self.D3 = DownSampling(256)\n",
    "        self.C4 = Conv(256, 512)\n",
    "        self.D4 = DownSampling(512)\n",
    "        self.C5 = Conv(512, 1024)\n",
    "\n",
    "        # 4次上采样\n",
    "        self.U1 = UpSampling(1024)\n",
    "        self.C6 = Conv(1024, 512)\n",
    "        self.U2 = UpSampling(512)\n",
    "        self.C7 = Conv(512, 256)\n",
    "        self.U3 = UpSampling(256)\n",
    "        self.C8 = Conv(256, 128)\n",
    "        self.U4 = UpSampling(128)\n",
    "        self.C9 = Conv(128, 64)\n",
    "\n",
    "        self.Th = torch.nn.Sigmoid()\n",
    "        self.pred = torch.nn.Conv2d(64, 3, 3, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 下采样部分\n",
    "        R1 = self.C1(x)\n",
    "        R2 = self.C2(self.D1(R1))\n",
    "        R3 = self.C3(self.D2(R2))\n",
    "        R4 = self.C4(self.D3(R3))\n",
    "        Y1 = self.C5(self.D4(R4))\n",
    "\n",
    "        # 上采样部分\n",
    "        # 上采样的时候需要拼接起来\n",
    "        O1 = self.C6(self.U1(Y1, R4))\n",
    "        O2 = self.C7(self.U2(O1, R3))\n",
    "        O3 = self.C8(self.U3(O2, R2))\n",
    "        O4 = self.C9(self.U4(O3, R1))\n",
    "        return self.Th(self.pred(O4))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6919579a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T13:56:37.353665Z",
     "iopub.status.busy": "2023-03-18T13:56:37.353337Z",
     "iopub.status.idle": "2023-03-18T13:56:39.969440Z",
     "shell.execute_reply": "2023-03-18T13:56:39.968438Z"
    },
    "papermill": {
     "duration": 2.622853,
     "end_time": "2023-03-18T13:56:39.972120",
     "exception": false,
     "start_time": "2023-03-18T13:56:37.349267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = UNet().cuda()\n",
    "loss_func = nn.MSELoss()\n",
    "best_train_loss = float('inf')\n",
    "best_val_loss = float('inf')\n",
    "lr = 1e-4\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=1e-4)\n",
    "train_dataloader = trainloader1\n",
    "val_dataloader = valloader\n",
    "#test_dataloader = testloader\n",
    "epochs = train_number_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc5d4b2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T13:56:39.980920Z",
     "iopub.status.busy": "2023-03-18T13:56:39.980549Z",
     "iopub.status.idle": "2023-03-18T13:56:39.997663Z",
     "shell.execute_reply": "2023-03-18T13:56:39.996484Z"
    },
    "papermill": {
     "duration": 0.024049,
     "end_time": "2023-03-18T13:56:39.999775",
     "exception": false,
     "start_time": "2023-03-18T13:56:39.975726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Pre_train(trainloader, valloader, model, loss_func, optimizer):\n",
    "    global best_train_loss\n",
    "    global best_val_loss\n",
    "    device = torch.device('cuda')\n",
    "    model = model.to(device)\n",
    "    for epoch in range(0, epochs):\n",
    "        # train part\n",
    "        total_train_loss = 0\n",
    "        counter1 = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            input_pic, label = data\n",
    "            #转移到GPU上，类型变为float以与模型参数类型匹配\n",
    "            input_pic, label = input_pic.to(device, dtype=torch.float), label.to(device, dtype=torch.float)\n",
    "            \n",
    "            \n",
    "            # output 已经双线性插值 进网络重建，得到三通道图片\n",
    "            output = model(input_pic)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss = loss_func(output, label)\n",
    "            loss.requires_grad_(True)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "            counter1 += 1\n",
    "\n",
    "        # val part\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        \n",
    "        #初始化三通道PSNR值与CPSNR值\n",
    "        total_psnr_r = 0\n",
    "        total_psnr_g = 0\n",
    "        total_psnr_b = 0\n",
    "        total_cpsnr = 0\n",
    "        \n",
    "        counter2 = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for j, data2 in enumerate(valloader, 0):\n",
    "                input_pic2, label2 = data2\n",
    "                \n",
    "                #CFA滤波与双线性插值的过程已在val_data_get函数中完成\n",
    "                input_pic2, label2 = input_pic2.to(device, dtype=torch.float), label2.to(device, dtype=torch.float)\n",
    "                # 进网络\n",
    "                \n",
    "                output2 = model(input_pic2)\n",
    "                \n",
    "                # RGGB采样\n",
    "                output2 = output2.cuda()\n",
    "                \n",
    "                loss2 = loss_func(output2, label2)\n",
    "                \n",
    "                total_val_loss += loss2.item()\n",
    "                \n",
    "                #为计算PSNR部分而进行MSE的计算\n",
    "                \n",
    "                #RGB三通道的MSE值\n",
    "                \n",
    "                mse_r = loss_func(output2[:, 0, :, :],\n",
    "                                 label2[:, 0, :, :])\n",
    "                mse_g = loss_func(output2[:, 1, :, :],\n",
    "                                 label2[:, 1, :, :])\n",
    "                mse_b = loss_func(output2[:, 2, :, :],\n",
    "                                 label2[:, 2, :, :])\n",
    "                #CPSNR，即三通道PSNR值的平均值\n",
    "                cmse = loss_func(output2[:, :, :, :],\n",
    "                                 label2[:, :, :, :])\n",
    "                \n",
    "                #计算所有图片RGB三通道的PSNR值及CPSNR之和\n",
    "                if mse_r.item() < 1.0e-10:  # 均方误差小到过分了\n",
    "                    total_psnr_r += 100\n",
    "                else:\n",
    "                    total_psnr_r += 20 * math.log10(1 / math.sqrt(mse_r.item()))\n",
    "                \n",
    "                if mse_g.item() < 1.0e-10:  # 均方误差小到过分了\n",
    "                    total_psnr_g += 100\n",
    "                else:\n",
    "                    total_psnr_g += 20 * math.log10(1 / math.sqrt(mse_g.item()))\n",
    "                \n",
    "                if mse_b.item() < 1.0e-10:  # 均方误差小到过分了\n",
    "                    total_psnr_b += 100\n",
    "                else:\n",
    "                    total_psnr_b += 20 * math.log10(1 / math.sqrt(mse_b.item()))\n",
    "                \n",
    "                if cmse.item() < 1.0e-10:  # 均方误差小到过分了\n",
    "                    total_cpsnr += 100\n",
    "                else:\n",
    "                    total_cpsnr += 20 * math.log10(1 / math.sqrt(cmse.item()))\n",
    "            \n",
    "                counter2 += 1\n",
    "        \n",
    "                \n",
    "            train_loss_avg = total_train_loss / counter1\n",
    "            val_loss_avg = total_val_loss / counter2\n",
    "            \n",
    "            #计算所有图片RGB三通道的PSNR值及CPSNR之均值\n",
    "            psnr_r_avg = total_psnr_r / counter2\n",
    "            psnr_g_avg = total_psnr_g / counter2\n",
    "            psnr_b_avg = total_psnr_b / counter2\n",
    "            cpsnr_avg = total_cpsnr / counter2\n",
    "            \n",
    "            print(\"Epoch number: {} , Train loss: {:.4f}, Val loss: {:.4f}, \\nPSNR_R: {:.4f}, PSNR_G: {:.4f}, PSNR_B: {:.4f}, CPSNR: {:.4f}\\n\".format(epoch, train_loss_avg, val_loss_avg, psnr_r_avg, psnr_g_avg, psnr_b_avg, cpsnr_avg))        \n",
    "\n",
    "        if val_loss_avg < best_val_loss:\n",
    "            best_val_loss = val_loss_avg\n",
    "            torch.save(net.state_dict(), '/kaggle/working/model/best_pretrain_unet.pth')\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16.307454,
   "end_time": "2023-03-18T13:56:42.228791",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-18T13:56:25.921337",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
